from basicsr.utils.options import parse_options
from torch.utils.data import DataLoader
from realesrgan.data.telehyper_dataset import TeleHyperDataset
from realesrgan.models.realesrnet_model import RealESRNetModel
import os
import cv2
import numpy as np
import torch
import pandas as pd
import random
from basicsr.data.degradations import random_add_gaussian_noise_pt, random_add_poisson_noise_pt
from basicsr.utils import DiffJPEG, USMSharp, img2tensor, tensor2img
from basicsr.utils.img_process_util import filter2D
from torch.nn import functional as F
from realesrgan.data.telehyper_dataset import PairedImageDataset
from scripts.color_align import calculate_image_differences_rgb
from tqdm import tqdm
# åˆå§‹åŒ–æ•°æ®é›†
opt_dataset = {
    'dataroot_gt': '/data2/sqq/blur_kernel/',  # e.g., '/data/train'
    'meta_info': '/data2/dataset/HSI_dataset/hdr_img_paths.txt', # _colorFreq '/home/sunqq/sqq/Real-ESRGAN/results/HDR_color/meta_info_color_20250519.txt', # ,'/data2/dataset/20250519/20250519HDR/meta_info_20250519.txt', #
    'io_backend': {'type': 'disk'},
    'use_hflip': True,
    'use_rot': True,
    'save_degraded': True,  # å¯ç”¨ä¿å­˜åŠŸèƒ½
    'degraded_dir': 'results/degraded_pairs',  # ä¿å­˜è·¯å¾„
     # ç¬¬äºŒæ¬¡é€€åŒ–å‚æ•°
    'kernel_list2': ['iso', 'aniso', 'generalized_iso', 'generalized_aniso', 'plateau_iso', 'plateau_aniso'],
    'kernel_prob2': [0.01, 0.25, 0.12, 0.03, 0.12, 0.03],
    'blur_sigma2': [0.0, 0.01],#[0.2, 1.5],
    'betag_range2': [0.5, 4],
    'betap_range2': [1, 2],
    'sinc_prob2': 0.1,   # 0.1
    'final_sinc_prob': 0.8,
}
import yaml

# 1. ç›´æ¥åŠ è½½é…ç½®
config_path = './options/train_realesrnet_x4plus.yml'
with open(config_path, 'r') as f:
    opt = yaml.safe_load(f)

# 2. è®¾ç½®å¿…è¦é»˜è®¤å€¼
opt.setdefault('is_train', True)
opt.setdefault('dist', False)
opt['name'] = opt.get('name', 'telehyper_train')
opt['save_degraded'] = True  # å¯ç”¨ä¿å­˜é€€åŒ–å›¾åƒ
opt['degraded_dir'] = '/data2/dataset/degtade_results/all/source'  # ä¿å­˜è·¯å¾„
opt['training'] = False
opt['type_prob'] = [0.0, 0.0, 1.0]
opt['color_align'] = True
# 3. åˆå§‹åŒ–æ¨¡å‹

def estimate_gaussian_noise(img):
    """
    ä¼°è®¡é«˜æ–¯å™ªå£°å¼ºåº¦ï¼ˆæ ‡å‡†å·®ï¼‰
    """
    # è½¬æ¢ä¸ºç°åº¦ & æµ®ç‚¹å‹
    if len(img.shape) == 3:
        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY).astype(np.float32)
    else:
        img_gray = img.astype(np.float32)

    # ç”¨é«˜æ–¯å¹³æ»‘åå‡å»åŸå›¾å¾—åˆ°æ®‹å·®
    smoothed = cv2.GaussianBlur(img_gray, (3, 3), 0)
    residual = img_gray - smoothed

    # è®¡ç®—æ®‹å·®çš„æ ‡å‡†å·®
    sigma = np.std(residual)
    return sigma


def estimate_poisson_noise(img):
    """
    ä¼°è®¡æ³Šæ¾å™ªå£°å¼ºåº¦ï¼ˆå‡å€¼-æ–¹å·®æ‹Ÿåˆç³»æ•°ï¼‰
    """
    # è½¬æ¢ä¸ºç°åº¦ & æµ®ç‚¹å‹
    if len(img.shape) == 3:
        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY).astype(np.float32)
    else:
        img_gray = img.astype(np.float32)

    # å°†å›¾åƒåˆ’åˆ†ä¸ºå¤šä¸ªå°å—ï¼Œç»Ÿè®¡æ¯å—çš„å‡å€¼å’Œæ–¹å·®
    block_size = 16
    h, w = img_gray.shape
    means = []
    variances = []

    for y in range(0, h - block_size, block_size):
        for x in range(0, w - block_size, block_size):
            block = img_gray[y:y+block_size, x:x+block_size]
            mean = np.mean(block)
            var = np.var(block)
            means.append(mean)
            variances.append(var)

    means = np.array(means)
    variances = np.array(variances)

    # æ‹Ÿåˆï¼šVar â‰ˆ Î» * Mean
    if np.sum(means) == 0:
        lambda_poisson = 0
    else:
        lambda_poisson = np.sum(variances) / np.sum(means)
    return lambda_poisson


def estimate_salt_pepper_noise(img):
    """
    ä¼°è®¡æ¤’ç›å™ªå£°å¼ºåº¦ï¼ˆæå€¼åƒç´ æ¯”ä¾‹ï¼‰
    """
    # è½¬æ¢ä¸ºç°åº¦
    if len(img.shape) == 3:
        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    else:
        img_gray = img

    total_pixels = img_gray.size
    salt = np.sum(img_gray == 255)
    pepper = np.sum(img_gray == 0)
    noise_ratio = (salt + pepper) / total_pixels
    return noise_ratio


def estimate_noise_all(image_path):
    """
    åŒæ—¶ä¼°è®¡é«˜æ–¯ã€æ³Šæ¾ã€æ¤’ç›å™ªå£°å¼ºåº¦
    """
    img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)
    if img is None:
        # print("âŒ æ— æ³•è¯»å–å›¾åƒï¼š", image_path)
        return 5, 0.1, 1

    # print(f"ğŸ“· å›¾åƒ: {image_path}")

    gaussian_sigma = estimate_gaussian_noise(img)
    # print(f"ğŸŒ¿ é«˜æ–¯å™ªå£°ä¼°è®¡ Ïƒ: {gaussian_sigma:.4f}")

    # poisson_lambda = estimate_poisson_noise(img)
    # # print(f"ğŸŒ± æ³Šæ¾å™ªå£°ä¼°è®¡ Î»: {poisson_lambda:.4f}")

    # sp_ratio = estimate_salt_pepper_noise(img)
    # print(f"ğŸ§‚ æ¤’ç›å™ªå£°ä¼°è®¡ æ¯”ä¾‹: {sp_ratio*100:.2f}%")

    return gaussian_sigma#, poisson_lambda, sp_ratio

class TelehyperData():
    def __init__(self, opt):
        self.usm_sharpener = USMSharp().cuda()  # do usm sharpening
        self.queue_size = opt.get('queue_size', 180)
        self.save_degraded = opt.get('save_degraded', False)  # æ–°å¢é…ç½®é¡¹
        self.degraded_dir = opt.get('degraded_dir', '/home/sunqq/sqq/Real-ESRGAN/results/degraded')  # ä¿å­˜è·¯å¾„

        if self.save_degraded and not os.path.exists(self.degraded_dir):
            os.makedirs(self.degraded_dir, exist_ok=True)
        self.device = 'cuda:0'
        self.opt = opt

    @torch.no_grad()
    def feed_data(self, data):
        """Accept data from dataloader, and then add two-order degradations to obtain LQ images.
        """
        # training data synthesis
        self.gt = data['gt'].to(self.device)
        # USM sharpen the GT images
        if self.opt['gt_usm'] is True:
            self.gt = self.usm_sharpener(self.gt)

        self.kernel1 = data['kernel1'].to(self.device)
        self.kernel2 = data['kernel2'].to(self.device)
        self.sinc_kernel = data['sinc_kernel'].to(self.device)
        color_diff_dict = opt['color_diff_dict']

        ori_h, ori_w = self.gt.size()[2:4]
        # ----------------------- The first degradation process ----------------------- #
        updown_type = random.choices(['kernel', 'gaussian', 'poisson'], self.opt['type_prob'])[0]
        if updown_type == 'kernel':
            # blur
            out = filter2D(self.gt, self.kernel1)
            out = self.gt
        elif updown_type == 'gaussian':
            out = random_add_gaussian_noise_pt(
                self.gt, sigma_range=self.opt['noise_range'], clip=True, rounds=False, gray_prob=0.5)
        else:
            out = random_add_poisson_noise_pt(
                self.gt,
                scale_range=self.opt['poisson_scale_range'],
                gray_prob=0.5,
                clip=True,
                rounds=False)
        # clamp and round
        self.lq = torch.clamp((out * 255.0).round(), 0, 255) / 255.

        # random crop
        # gt_size = self.opt['gt_size']
        # self.gt, self.lq = paired_random_crop(self.gt, self.lq, gt_size, self.opt['scale'])
        if self.save_degraded:
            self._save_degraded_pairs(data['gt_path'], self.gt, self.lq)
        # training pair pool
        # self._dequeue_and_enqueue()
        # self.lq = self.lq.contiguous()  # for the warning: grad and param do not obey the gradient layout contract

    def _save_degraded_pairs(self, gt_paths, gt_tensor, lq_tensor):
        """ä¿å­˜HQ-LQå›¾åƒå¯¹"""
        for i in range(len(gt_paths)):
            # è·å–æ–‡ä»¶å
            img_name = os.path.splitext(os.path.basename(gt_paths[i]))[0]

            # è½¬æ¢tensorä¸ºnumpyå›¾åƒ
            gt_img = tensor2img(gt_tensor[i:i+1], rgb2bgr=True, out_type=np.uint8)
            lq_img = tensor2img(lq_tensor[i:i+1], rgb2bgr=True, out_type=np.uint8)

            # ä¿å­˜å›¾åƒ
            # cv2.imwrite(
            #     os.path.join(self.degraded_dir, f'{img_name}_HQ.png'),
            #     gt_img
            # )
            cv2.imwrite(
                os.path.join(self.degraded_dir, f'{img_name}_LQ.png'),
                lq_img
            )
            print(os.path.join(self.degraded_dir, f'{img_name}_LQ.png'))


def extract_parameter_ranges_quantile(
    df: pd.DataFrame,
    lower: float = 0.20,
    upper: float = 0.80,
    std_threshold: float = 3.0,
    alt_lower: float = 0.40,
    alt_upper: float = 0.60
) -> tuple:
    """
    æå–é¢œè‰²å·®å¼‚å’Œå™ªå£°ä¼°è®¡çš„å‚æ•°åˆ†å¸ƒèŒƒå›´ï¼ˆä½¿ç”¨åˆ†ä½æ•°ï¼Œé¿å…ç¦»ç¾¤ç‚¹å½±å“ï¼‰ã€‚
    è‹¥æŸåˆ—æ ‡å‡†å·®è¶…è¿‡é˜ˆå€¼ï¼Œä½¿ç”¨40%-60%åˆ†ä½æ•°é¿å…ç¦»ç¾¤å€¼å¹²æ‰°ã€‚

    Returns:
        color_ranges_dict: dict[str, list]  # æ¯ä¸ªé¢œè‰²å‚æ•°çš„[low, high]
        gaussian_sigma_range: list[float]   # å™ªå£°å‚æ•°çš„[low, high]
    """
    color_keys = [
        'brightness_diff_L_mean',
        'contrast_diff_L_std',
        'color_diff_a_mean',
        'color_diff_b_mean',
        'saturation_diff_S_mean'
    ]

    color_ranges_dict = {}
    for key in color_keys:
        std_val = df[key].std()
        if std_val > std_threshold:
            q_low, q_high = alt_lower, alt_upper
        else:
            q_low, q_high = lower, upper
        color_ranges_dict[key] = list(df[key].quantile([q_low, q_high]).values)

    # å¯¹ gaussian_sigma ä¹Ÿä½¿ç”¨ç±»ä¼¼åˆ¤æ–­ï¼ˆå¦‚æœ‰éœ€è¦ï¼‰
    sigma_std = df['gaussian_sigma'].std()
    if sigma_std > std_threshold:
        sigma_range = list(df['gaussian_sigma'].quantile([alt_lower, alt_upper]).values)
    else:
        sigma_range = list(df['gaussian_sigma'].quantile([lower, upper]).values)

    return color_ranges_dict, sigma_range

# 5. è®­ç»ƒå¾ªç¯
# for epoch in range(opt.get('epochs', 100)):
# model = TelehyperData(opt)

paired_dataset_opt = {
    'dataroot_source': '/data2/dataset/HSI_dataset/HDR_img',
    'dataroot_target': '/data2/dataset/HSI_dataset/Glasses_img',
    'meta_info': '/data2/dataset/HSI_dataset/glasses_img_paths.txt',
}

paired_dataset = PairedImageDataset(paired_dataset_opt)
dataloader = DataLoader(paired_dataset, batch_size=1, shuffle=False)
records = []
for i, data in enumerate(tqdm(dataloader)):
    src_path = data['source_path'][0]
    tgt_path = data['target_path'][0]
    img_src = data['img_source'][0].numpy().transpose(1, 2, 0)
    img_tgt = data['img_target'][0].numpy().transpose(1, 2, 0)

    # é¢œè‰²å·®å¼‚
    color_diff = calculate_image_differences_rgb(img_src, img_tgt)

    # å™ªå£°ä¼°è®¡
    sigma = estimate_noise_all(src_path)  # or pass img_src if needed

    record = {
        'source_path': src_path,
        'target_path': tgt_path,
        'gaussian_sigma': sigma,
        **color_diff
    }

    records.append(record)
    # if i>10:
    #     break

# ä¿å­˜ä¸º DataFrame
df = pd.DataFrame(records)
summary = df.describe(percentiles=[0.20, 0.80]).T
summary = summary[['mean', 'std', '20%', '80%']]
print(summary)
color_ranges, noise_range = extract_parameter_ranges_quantile(df, 0.40, 0.60, 2.5, 0.45, 0.55)
opt['color_diff_dict'] = color_ranges
opt['noise_range'] = noise_range

model = RealESRNetModel(opt)
dataset = TeleHyperDataset(opt_dataset)
dataloader = DataLoader(dataset, batch_size=opt.get('batch_size', 1))
num = 0
for data in dataloader:
    # lq_path = os.path.join('/data2/dataset/HSI_dataset/Glasses_img', os.path.basename(data['gt_path'][0])).replace('.png', '.jpg')
    # gaussian_sigma, poisson_lambda, sp_ratio = estimate_noise_all(lq_path)
    # opt['noise_range'] = [gaussian_sigma-2, gaussian_sigma+3]
    # opt['poisson_scale_range'] = [poisson_lambda-0.02, poisson_lambda+0.03]

    print(num)  # æ‰“å°æ•°æ®çš„é”®
    model.feed_data(data)
    num += 1
    # if num>1:
    #     break